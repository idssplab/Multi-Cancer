{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from warnings import filterwarnings\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset import TCGA_Program_Dataset\n",
    "from datasets_manager import TCGA_Balanced_Datasets_Manager, TCGA_Datasets_Manager\n",
    "from lit_models import LitFullModel\n",
    "from model import Classifier, Feature_Extractor, Graph_And_Clinical_Feature_Extractor, Task_Classifier\n",
    "from utils import config_add_subdict_key, get_logger, override_n_genes, set_random_seed, setup_logging\n",
    "import shap\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "SEED = 1126\n",
    "set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_models_and_optimizers(config: dict):\n",
    "    models: dict[str, torch.nn.Module] = {}\n",
    "    optimizers: dict[str, torch.optim.Optimizer] = {}\n",
    "\n",
    "    # Setup models. Do not use getattr() for better IDE support.\n",
    "    for model_name, kargs in config['models'].items():\n",
    "        if model_name == 'Graph_And_Clinical_Feature_Extractor':\n",
    "            models['feat_ext'] = Graph_And_Clinical_Feature_Extractor(**kargs)\n",
    "        elif model_name == 'Feature_Extractor':\n",
    "            models['feat_ext'] = Feature_Extractor(**kargs)\n",
    "        elif model_name == 'Task_Classifier':\n",
    "            models['clf'] = Task_Classifier(**kargs)\n",
    "        elif model_name == 'Classifier':\n",
    "            models['clf'] = Classifier(**kargs)\n",
    "        else:\n",
    "            raise ValueError(f'Unknown model type: {model_name}')\n",
    "\n",
    "    # Setup optimizers. If the key is 'all', the optimizer will be applied to all models.\n",
    "    for key, optim_dict in config['optimizers'].items():\n",
    "        opt_name = next(iter(optim_dict))\n",
    "        if key == 'all':\n",
    "            params = [param for model in models.values() for param in model.parameters()]\n",
    "            optimizers[key] = getattr(torch.optim, opt_name)(params, **optim_dict[opt_name])\n",
    "        else:\n",
    "            optimizers[key] = getattr(torch.optim, opt_name)(models[key].parameters(), **optim_dict[opt_name])\n",
    "\n",
    "    # Add models' structure to config for logging. TODO: Prettify.\n",
    "    for model_name, torch_model in models.items():\n",
    "        config[f'model.{model_name}'] = str(torch_model)\n",
    "    return models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]\tUsing Random Seed 1126 for this experiment\n",
      "[INFO]\tCreating a TCGA Program Dataset with 3 Projects...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select a config file.\n",
    "\n",
    "config_path = '/home/zow/Multi-Cancer/config/light/MTL_TCGA.yaml'\n",
    "config = config_path\n",
    "with open(config, 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "override_n_genes(config)                                                    # For multi-task graph models.\n",
    "config_name =config_path.split('/')[-1].split('.')[0]\n",
    "\n",
    "# Setup logging.\n",
    "setup_logging(log_path := f'Logs/{config_name}/{datetime.now():%Y-%m-%dT%H:%M:%S}/')\n",
    "logger = get_logger(config_name)\n",
    "logger.info(f'Using Random Seed {SEED} for this experiment')\n",
    "get_logger('lightning.pytorch.accelerators.cuda', log_level='WARNING')      # Disable cuda logging.\n",
    "filterwarnings('ignore', r'.*Skipping val loop.*')                          # Disable val loop warning.\n",
    "\n",
    "# Create dataset manager.\n",
    "#here use torch lightning DS\n",
    "data = {'TCGA_BLC': TCGA_Program_Dataset(**config['datasets'])}\n",
    "if 'TCGA_Balanced_Datasets_Manager' == config['datasets_manager']['type']:\n",
    "    manager = TCGA_Balanced_Datasets_Manager(datasets=data, config=config_add_subdict_key(config))\n",
    "else:\n",
    "    manager = TCGA_Datasets_Manager(datasets=data, config=config_add_subdict_key(config))\n",
    "\n",
    "valid_results = []\n",
    "# Cross validation.\n",
    "for key, values in manager['TCGA_BLC']['dataloaders'].items():\n",
    "    if isinstance(key, int) and config['cross_validation']:\n",
    "        pass\n",
    "    #     models, optimizers = create_models_and_optimizers(config)\n",
    "    #     lit_model = LitFullModel(models, optimizers, config)\n",
    "    #     trainer = pl.Trainer(                                               # Create sub-folders for each fold.\n",
    "    #         default_root_dir=log_path,\n",
    "    #         max_epochs=config['max_epochs'],\n",
    "    #         log_every_n_steps=1,\n",
    "    #         enable_model_summary=False,\n",
    "    #         enable_checkpointing=False,\n",
    "    #     )\n",
    "    #     trainer.fit(lit_model, train_dataloaders=values['train'], val_dataloaders=values['valid'])\n",
    "    #     trainer.test(lit_model, dataloaders=values['valid'], verbose=False) #verbose true prints the validation results for each fold\n",
    "    #     # print validation results\n",
    "        \n",
    "    #     valid_results.append(trainer.test(lit_model, dataloaders=values['valid'], verbose=False)[0])\n",
    "            \n",
    "        \n",
    "        \n",
    "    elif key == 'train':\n",
    "        train = values\n",
    "    elif key == 'test':\n",
    "        test = values\n",
    "\n",
    "\n",
    "\n",
    "# Train the final model.\n",
    "models, optimizers = create_models_and_optimizers(config)\n",
    "lit_model = LitFullModel(models, optimizers, config)\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir=log_path,\n",
    "    max_epochs=config['max_epochs'],\n",
    "    enable_progress_bar=False,\n",
    "    log_every_n_steps=1,\n",
    "    logger=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "progpred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
