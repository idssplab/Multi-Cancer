{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. The SHAP analysis is interesting, however it could be made stronger by looking into the correlations of features and/or the stability of SHAP scores for the same MTL model across different folds/seeds. Basically, are the differences in SHAP scores statistically significant?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from warnings import filterwarnings\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset import TCGA_Program_Dataset\n",
    "from datasets_manager import TCGA_Balanced_Datasets_Manager, TCGA_Datasets_Manager\n",
    "from lit_models import LitFullModel\n",
    "from model import Classifier, Feature_Extractor, Graph_And_Clinical_Feature_Extractor, Task_Classifier\n",
    "from utils import config_add_subdict_key, get_logger, override_n_genes, set_random_seed, setup_logging\n",
    "import shap\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "SEED = 1126\n",
    "set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_models_and_optimizers(config: dict):\n",
    "    models: dict[str, torch.nn.Module] = {}\n",
    "    optimizers: dict[str, torch.optim.Optimizer] = {}\n",
    "\n",
    "    # Setup models. Do not use getattr() for better IDE support.\n",
    "    for model_name, kargs in config['models'].items():\n",
    "        if model_name == 'Graph_And_Clinical_Feature_Extractor':\n",
    "            models['feat_ext'] = Graph_And_Clinical_Feature_Extractor(**kargs)\n",
    "        elif model_name == 'Feature_Extractor':\n",
    "            models['feat_ext'] = Feature_Extractor(**kargs)\n",
    "        elif model_name == 'Task_Classifier':\n",
    "            models['clf'] = Task_Classifier(**kargs)\n",
    "        elif model_name == 'Classifier':\n",
    "            models['clf'] = Classifier(**kargs)\n",
    "        else:\n",
    "            raise ValueError(f'Unknown model type: {model_name}')\n",
    "\n",
    "    # Setup optimizers. If the key is 'all', the optimizer will be applied to all models.\n",
    "    for key, optim_dict in config['optimizers'].items():\n",
    "        opt_name = next(iter(optim_dict))\n",
    "        if key == 'all':\n",
    "            params = [param for model in models.values() for param in model.parameters()]\n",
    "            optimizers[key] = getattr(torch.optim, opt_name)(params, **optim_dict[opt_name])\n",
    "        else:\n",
    "            optimizers[key] = getattr(torch.optim, opt_name)(models[key].parameters(), **optim_dict[opt_name])\n",
    "\n",
    "    # Add models' structure to config for logging. TODO: Prettify.\n",
    "    for model_name, torch_model in models.items():\n",
    "        config[f'model.{model_name}'] = str(torch_model)\n",
    "    return models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select a config file.\n",
    "\n",
    "config_path = '/home/zow/Multi-Cancer/config/light/MTL_TCGA.yaml'\n",
    "config = config_path\n",
    "with open(config, 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "override_n_genes(config)                                                    # For multi-task graph models.\n",
    "config_name =config_path.split('/')[-1].split('.')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]\tUsing Random Seed 1126 for this experiment\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Setup logging.\n",
    "setup_logging(log_path := f'Logs/{config_name}/{datetime.now():%Y-%m-%dT%H:%M:%S}/')\n",
    "logger = get_logger(config_name)\n",
    "logger.info(f'Using Random Seed {SEED} for this experiment')\n",
    "get_logger('lightning.pytorch.accelerators.cuda', log_level='WARNING')      # Disable cuda logging.\n",
    "filterwarnings('ignore', r'.*Skipping val loop.*')                          # Disable val loop warning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]\tCreating a TCGA Program Dataset with 3 Projects...\n",
      "[INFO]\tAll files are downloaded for TCGA-BRCA\n",
      "[INFO]\tCreating 1093 cases for TCGA-BRCA...\n",
      "[INFO]\tUsing genomic tpm cache files created at 2024-02-23 10:53:54 for TCGA-BRCA\n",
      "[INFO]\tUsing clinical cache files created at 2024-02-23 10:54:21 for TCGA-BRCA\n",
      "[INFO]\tUsing vital status cache files created at 2024-02-23 10:54:29 for TCGA-BRCA\n",
      "[INFO]\tUsing overall survival cache files created at 2024-02-23 10:54:37 for TCGA-BRCA\n",
      "[INFO]\tUsing disease specific survival cache files created at 2024-02-23 10:54:46 for TCGA-BRCA\n",
      "[INFO]\tUsing survival time cache files created at 2024-02-23 10:54:53 for TCGA-BRCA\n",
      "[INFO]\tUsing primary site cache files created at 2024-02-23 10:55:06 for TCGA-BRCA\n",
      "[INFO]\tAll files are downloaded for TCGA-LUAD\n",
      "[INFO]\tCreating 510 cases for TCGA-LUAD...\n",
      "[INFO]\tUsing genomic tpm cache files created at 2024-02-23 11:41:50 for TCGA-LUAD\n",
      "[INFO]\tUsing clinical cache files created at 2024-02-23 11:41:58 for TCGA-LUAD\n",
      "[INFO]\tUsing vital status cache files created at 2024-02-23 11:41:59 for TCGA-LUAD\n",
      "[INFO]\tUsing overall survival cache files created at 2024-02-23 11:42:00 for TCGA-LUAD\n",
      "[INFO]\tUsing disease specific survival cache files created at 2024-02-23 11:42:02 for TCGA-LUAD\n",
      "[INFO]\tUsing survival time cache files created at 2024-02-23 11:42:03 for TCGA-LUAD\n",
      "[INFO]\tUsing primary site cache files created at 2024-02-23 11:42:06 for TCGA-LUAD\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create dataset manager.\n",
    "#here use torch lightning DS\n",
    "data = {'TCGA_BLC': TCGA_Program_Dataset(**config['datasets'])}\n",
    "if 'TCGA_Balanced_Datasets_Manager' == config['datasets_manager']['type']:\n",
    "    manager = TCGA_Balanced_Datasets_Manager(datasets=data, config=config_add_subdict_key(config))\n",
    "else:\n",
    "    manager = TCGA_Datasets_Manager(datasets=data, config=config_add_subdict_key(config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: saved in Logs/MTL_TCGA/2024-03-11T13:43:36/\n",
      "Epoch 49: 100%|██████████| 10/10 [00:00<00:00, 24.75it/s, v_num=28, loss=0.406]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 10/10 [00:00<00:00, 24.66it/s, v_num=28, loss=0.406]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: saved in Logs/MTL_TCGA/2024-03-11T13:43:36/\n",
      "Epoch 49: 100%|██████████| 10/10 [00:00<00:00, 23.02it/s, v_num=29, loss=0.405]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 10/10 [00:00<00:00, 22.94it/s, v_num=29, loss=0.405]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: saved in Logs/MTL_TCGA/2024-03-11T13:43:36/\n",
      "Epoch 49: 100%|██████████| 10/10 [00:00<00:00, 24.43it/s, v_num=30, loss=0.384]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 10/10 [00:00<00:00, 24.34it/s, v_num=30, loss=0.384]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: saved in Logs/MTL_TCGA/2024-03-11T13:43:36/\n",
      "Epoch 42:  90%|█████████ | 9/10 [00:00<00:00, 39.84it/s, v_num=31, loss=0.395] "
     ]
    }
   ],
   "source": [
    "\n",
    "valid_results = []\n",
    "# Cross validation.\n",
    "all_shap_values_folds = []\n",
    "all_project_ids = []\n",
    "for key, values in manager['TCGA_BLC']['dataloaders'].items():\n",
    "    if isinstance(key, int) and config['cross_validation']:\n",
    "        pass\n",
    "        models, optimizers = create_models_and_optimizers(config)\n",
    "        lit_model = LitFullModel(models, optimizers, config)\n",
    "        trainer = pl.Trainer(                                               # Create sub-folders for each fold.\n",
    "            default_root_dir=\"\",#log_path,\n",
    "            max_epochs=config['max_epochs'],\n",
    "            log_every_n_steps=1,\n",
    "            enable_model_summary=False,\n",
    "            enable_checkpointing=False,\n",
    "        )\n",
    "        print(f'Fold {key}: saved in {log_path}')\n",
    "        trainer.fit(lit_model, train_dataloaders=values['train'], val_dataloaders=values['valid'])\n",
    "\n",
    "        \n",
    "        # get one batch of data\n",
    "        batch = next(iter(train))\n",
    "        (genomic, clinical, index, project_id), (overall_survival, survival_time, vital_status) = batch\n",
    "        # get the shap values\n",
    "        feat_extractor = models['feat_ext']\n",
    "        genomic_feat_ext = feat_extractor.genomic_feature_extractor        \n",
    "        explainer = shap.DeepExplainer(genomic_feat_ext, genomic)\n",
    "        #separate according to project_id\n",
    "        project_id = project_id.numpy()\n",
    "        all_project_ids.append(project_id)\n",
    "\n",
    "\n",
    "        shap_values = explainer.shap_values(genomic)\n",
    "        all_shap_values_folds.append(np.array(shap_values))\n",
    "        #print shape of shap values and project_id\n",
    "        print(np.array(shap_values).shape)\n",
    "        print(project_id.shape)\n",
    "        \n",
    "        \n",
    "    elif key == 'train':\n",
    "        train = values\n",
    "    elif key == 'test':\n",
    "        test = values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "len(all_shap_values_folds[0])\n",
    "all_shap_values_folds[0].shape\n",
    "\n",
    "\n",
    "#aggregate shap values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shap_values_folds_list = []\n",
    "for fold in range(len(all_shap_values_folds)):\n",
    "    shap_values = all_shap_values_folds[fold]\n",
    "    # average shap values collapsing the 1s dimension\n",
    "    shap_values = np.mean(shap_values, axis = 0)\n",
    "    print(shap_values.shape)\n",
    "    project_id = all_project_ids[fold]\n",
    "    # save shap values in different dfs, according to project id\n",
    "    for i in range(len(np.unique(project_id))):\n",
    "        # add project id as another column\n",
    "        shap_values_df = pd.DataFrame(shap_values)\n",
    "        shap_values_df['project_id'] = project_id\n",
    "        #shap_values_df.to_csv(f'shap_values_fold{fold}_project{i}.csv')\n",
    "    shap_values_df[\"Fold\"] = fold\n",
    "    all_shap_values_folds_list.append(shap_values_df)\n",
    "\n",
    "#concatenate all dfs\n",
    "all_shap_values_folds_df = pd.concat(all_shap_values_folds_list)\n",
    "all_shap_values_folds_df.to_csv('shap_values_all_folds.csv')\n",
    "all_shap_values_folds_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate according to project_id\n",
    "BRCA_shap_values = all_shap_values_folds_df[all_shap_values_folds_df['project_id'] == 0]\n",
    "COAD_shap_values = all_shap_values_folds_df[all_shap_values_folds_df['project_id'] == 2]\n",
    "LUAD_shap_values = all_shap_values_folds_df[all_shap_values_folds_df['project_id'] == 1]\n",
    "\n",
    "#drop project_id column\n",
    "BRCA_shap_values = BRCA_shap_values.drop(columns = ['project_id'])\n",
    "COAD_shap_values = COAD_shap_values.drop(columns = ['project_id'])\n",
    "LUAD_shap_values = LUAD_shap_values.drop(columns = ['project_id'])\n",
    "\n",
    "#relabel gene names\n",
    "\n",
    "BRCA_genes = ['ESR1', 'EFTUD2', 'HSPA8', 'STAU1', 'SHMT2', 'ACTB', 'GSK3B', 'YWHAB', 'UBXN6', 'PRKRA', 'BTRC', 'DDX23', 'SSR1', 'TUBA1C', 'SNIP1', 'SRSF5', 'ERBB2', 'MKI67', 'PGR', 'PLAU']\n",
    "LUAD_genes = ['HNRNPU', 'STAU1', 'KDM1A', 'SERBP1', 'DHX9', 'EMC1', 'SSR1', 'PUM1', 'CLTC', 'PRKRA', 'KRR1', 'OCIAD1', 'CDC73', 'SLC2A1', 'HIF1A', 'PKM', 'CADM1', 'EPCAM', 'ALCAM', 'PTK7']\n",
    "COAD_genes =  ['HNRNPL', 'HNRNPU', 'HNRNPA1', 'ZBTB2', 'SERBP1', 'RPL4', 'HNRNPK', 'HNRNPR', 'TFCP2', 'DHX9', 'RNF4', 'PUM1', 'ABCC1', 'CD44', 'ALCAM', 'ABCG2', 'ALDH1A1', 'ABCB1', 'EPCAM', 'PROM1']\n",
    "BRCA_shap_values.columns = BRCA_genes + ['Fold']\n",
    "COAD_shap_values.columns = COAD_genes + ['Fold']\n",
    "LUAD_shap_values.columns = LUAD_genes + ['Fold']\n",
    "\n",
    "\n",
    "# plot SHAP values for BRCA\n",
    "BRCA_shap_values = BRCA_shap_values.drop(columns = ['Fold'])\n",
    "BRCA_shap_values = BRCA_shap_values.T\n",
    "BRCA_shap_values['mean'] = BRCA_shap_values.mean(axis = 1)\n",
    "BRCA_shap_values = BRCA_shap_values.sort_values(by = 'mean', ascending = False)\n",
    "BRCA_shap_values = BRCA_shap_values.drop(columns = ['mean'])\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(BRCA_shap_values, cmap = 'coolwarm')\n",
    "plt.title('BRCA SHAP values')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#calculate stability accross folds\n",
    "# Calculate the mean and standard deviation of SHAP values for each feature across folds\n",
    "def calculate_stability(shap_df):\n",
    "    # separate according to fold and save in a list\n",
    "\n",
    "    means = shap_df.groupby('Fold').mean()\n",
    "    stds = shap_df.groupby('Fold').std()\n",
    "    cv = stds / means  # Coefficient of Variation\n",
    "    columns_names = shap_df.columns[:-1]\n",
    "\n",
    "    # Convert to DataFrame for easier handling and interpretation\n",
    "    stability_df = pd.DataFrame({\n",
    "        'mean_shap': means.mean(axis=0),  # Mean across samples, then across folds\n",
    "        'std_shap': stds.mean(axis=0),    # Std across samples, then across folds\n",
    "        'cv_shap': cv.mean(axis=0)        # CV across samples, then across folds\n",
    "    }, index=columns_names)  # Assuming feature names are the same across all folds\n",
    "\n",
    "    # Sort by CV for features\n",
    "    stability_df = stability_df.sort_values(by='cv_shap')\n",
    "    return stability_df\n",
    "\n",
    "\n",
    "\n",
    "# Plot the Coefficient of Variation (CV) for each feature\n",
    "def plot_SHAP_stability(stability_df, dataset_name = ''):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(x='cv_shap', y=stability_df.index, data=stability_df)\n",
    "    plt.title('Coefficient of Variation of SHAP Values Across Folds for ' + dataset_name)\n",
    "    plt.xlabel('Coefficient of Variation (CV)')\n",
    "    plt.ylabel('Features')\n",
    "    #plt.show()\n",
    "\n",
    "\n",
    "\n",
    "BRCA_stability = calculate_stability(BRCA_shap_values)\n",
    "COAD_stability = calculate_stability(COAD_shap_values)\n",
    "LUAD_stability = calculate_stability(LUAD_shap_values)\n",
    "\n",
    "\n",
    "plot_SHAP_stability(BRCA_stability, 'BRCA')\n",
    "plot_SHAP_stability(COAD_stability, 'COAD')\n",
    "plot_SHAP_stability(LUAD_stability, 'LUAD')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features with a high coefficient of variation (CV) are less stable across folds, meaning their importance varies more between different subsets of the data. In contrast, features with a low CV are more stable, suggesting consistent importance across different folds.\n",
    "\n",
    "By identifying which features are stable and which are not, you can better understand the reliability of your model's feature importance scores and potentially identify areas where your model's performance might be improved with more consistent or representative training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store all averaged SHAP values from all folds\n",
    "averaged_shap_values_all_folds = []\n",
    "\n",
    "for fold_shap_values in all_shap_values_folds:  # fold_shap_values shape is (8, 512, 20)\n",
    "    # Average across the outputs/classes (axis 0)\n",
    "    averaged_shap_values = np.mean(fold_shap_values, axis=0)\n",
    "    averaged_shap_values_all_folds.append(averaged_shap_values)\n",
    "\n",
    "# Concatenate and convert to DataFrame\n",
    "concatenated_averaged_shap_values = np.concatenate(averaged_shap_values_all_folds, axis=0)\n",
    "averaged_shap_values_df = pd.DataFrame(concatenated_averaged_shap_values)\n",
    "\n",
    "# 'averaged_shap_values_df' now contains the averaged SHAP values for all samples across all folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.001015</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>-0.031677</td>\n",
       "      <td>0.005340</td>\n",
       "      <td>-0.005632</td>\n",
       "      <td>-0.020547</td>\n",
       "      <td>-0.048760</td>\n",
       "      <td>0.019574</td>\n",
       "      <td>0.014512</td>\n",
       "      <td>0.031816</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>0.005286</td>\n",
       "      <td>-0.001798</td>\n",
       "      <td>-0.011941</td>\n",
       "      <td>-0.002266</td>\n",
       "      <td>-0.010339</td>\n",
       "      <td>-0.024124</td>\n",
       "      <td>0.028901</td>\n",
       "      <td>-0.006093</td>\n",
       "      <td>0.005533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.051731</td>\n",
       "      <td>0.006652</td>\n",
       "      <td>0.136839</td>\n",
       "      <td>-0.003894</td>\n",
       "      <td>0.010757</td>\n",
       "      <td>-0.013287</td>\n",
       "      <td>0.037974</td>\n",
       "      <td>-0.017151</td>\n",
       "      <td>-0.022757</td>\n",
       "      <td>-0.015226</td>\n",
       "      <td>-0.001958</td>\n",
       "      <td>0.002843</td>\n",
       "      <td>0.023895</td>\n",
       "      <td>0.024760</td>\n",
       "      <td>-0.015642</td>\n",
       "      <td>-0.002737</td>\n",
       "      <td>-0.016819</td>\n",
       "      <td>0.029769</td>\n",
       "      <td>-0.093086</td>\n",
       "      <td>0.008109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006235</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>-0.105235</td>\n",
       "      <td>0.002718</td>\n",
       "      <td>0.010556</td>\n",
       "      <td>-0.051326</td>\n",
       "      <td>0.037556</td>\n",
       "      <td>0.037840</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>-0.017308</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>-0.010183</td>\n",
       "      <td>0.022277</td>\n",
       "      <td>0.013243</td>\n",
       "      <td>-0.000137</td>\n",
       "      <td>-0.026663</td>\n",
       "      <td>-0.020180</td>\n",
       "      <td>-0.122443</td>\n",
       "      <td>0.004120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.030199</td>\n",
       "      <td>-0.002578</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>0.080181</td>\n",
       "      <td>0.037520</td>\n",
       "      <td>-0.032054</td>\n",
       "      <td>0.009461</td>\n",
       "      <td>-0.016316</td>\n",
       "      <td>-0.000577</td>\n",
       "      <td>-0.003060</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.025039</td>\n",
       "      <td>-0.015776</td>\n",
       "      <td>-0.006022</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.029983</td>\n",
       "      <td>-0.104112</td>\n",
       "      <td>-0.002858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.006524</td>\n",
       "      <td>-0.005861</td>\n",
       "      <td>-0.000665</td>\n",
       "      <td>0.010431</td>\n",
       "      <td>0.058351</td>\n",
       "      <td>0.037982</td>\n",
       "      <td>-0.014036</td>\n",
       "      <td>0.007418</td>\n",
       "      <td>-0.015662</td>\n",
       "      <td>-0.002117</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>0.028881</td>\n",
       "      <td>-0.015081</td>\n",
       "      <td>-0.004178</td>\n",
       "      <td>-0.010822</td>\n",
       "      <td>0.031147</td>\n",
       "      <td>-0.126427</td>\n",
       "      <td>0.003352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>-0.026646</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.055896</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.026589</td>\n",
       "      <td>-0.209201</td>\n",
       "      <td>0.066349</td>\n",
       "      <td>0.026715</td>\n",
       "      <td>0.008688</td>\n",
       "      <td>0.020754</td>\n",
       "      <td>-0.003117</td>\n",
       "      <td>-0.003833</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.017209</td>\n",
       "      <td>0.006311</td>\n",
       "      <td>-0.061827</td>\n",
       "      <td>-0.016674</td>\n",
       "      <td>-0.029071</td>\n",
       "      <td>0.289541</td>\n",
       "      <td>-0.021307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>-0.041878</td>\n",
       "      <td>0.022439</td>\n",
       "      <td>0.035915</td>\n",
       "      <td>-0.001384</td>\n",
       "      <td>0.026911</td>\n",
       "      <td>0.463933</td>\n",
       "      <td>-0.030851</td>\n",
       "      <td>-0.028827</td>\n",
       "      <td>-0.005917</td>\n",
       "      <td>-0.006023</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>-0.001256</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.042910</td>\n",
       "      <td>0.009608</td>\n",
       "      <td>-0.012760</td>\n",
       "      <td>-0.027474</td>\n",
       "      <td>-0.030275</td>\n",
       "      <td>-0.072761</td>\n",
       "      <td>-0.021650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>-0.010746</td>\n",
       "      <td>-0.003816</td>\n",
       "      <td>0.023448</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.002640</td>\n",
       "      <td>-0.183422</td>\n",
       "      <td>0.097341</td>\n",
       "      <td>0.033691</td>\n",
       "      <td>0.007331</td>\n",
       "      <td>0.023418</td>\n",
       "      <td>-0.001231</td>\n",
       "      <td>-0.008805</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.055271</td>\n",
       "      <td>0.005284</td>\n",
       "      <td>-0.060763</td>\n",
       "      <td>-0.021611</td>\n",
       "      <td>-0.032990</td>\n",
       "      <td>0.267477</td>\n",
       "      <td>-0.010844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>-0.113499</td>\n",
       "      <td>0.025413</td>\n",
       "      <td>-0.255962</td>\n",
       "      <td>-0.002498</td>\n",
       "      <td>-0.016057</td>\n",
       "      <td>0.508644</td>\n",
       "      <td>-0.026986</td>\n",
       "      <td>-0.080468</td>\n",
       "      <td>0.008861</td>\n",
       "      <td>-0.006110</td>\n",
       "      <td>-0.001233</td>\n",
       "      <td>0.008284</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>-0.009533</td>\n",
       "      <td>0.007906</td>\n",
       "      <td>-0.046510</td>\n",
       "      <td>0.662046</td>\n",
       "      <td>-0.027435</td>\n",
       "      <td>-0.079064</td>\n",
       "      <td>0.056893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>-0.002495</td>\n",
       "      <td>-0.002812</td>\n",
       "      <td>0.069646</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>-0.009951</td>\n",
       "      <td>-0.193975</td>\n",
       "      <td>0.074348</td>\n",
       "      <td>0.025062</td>\n",
       "      <td>0.008997</td>\n",
       "      <td>0.021850</td>\n",
       "      <td>-0.002650</td>\n",
       "      <td>-0.007210</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.056252</td>\n",
       "      <td>0.003287</td>\n",
       "      <td>-0.061900</td>\n",
       "      <td>-0.047085</td>\n",
       "      <td>-0.032097</td>\n",
       "      <td>0.159083</td>\n",
       "      <td>-0.006506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0   -0.001015  0.001499 -0.031677  0.005340 -0.005632 -0.020547 -0.048760   \n",
       "1   -0.051731  0.006652  0.136839 -0.003894  0.010757 -0.013287  0.037974   \n",
       "2    0.006235  0.002726 -0.105235  0.002718  0.010556 -0.051326  0.037556   \n",
       "3    0.000719  0.005442  0.030199 -0.002578  0.009095  0.080181  0.037520   \n",
       "4    0.003333  0.006524 -0.005861 -0.000665  0.010431  0.058351  0.037982   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "507 -0.026646  0.001125  0.055896  0.001351  0.026589 -0.209201  0.066349   \n",
       "508 -0.041878  0.022439  0.035915 -0.001384  0.026911  0.463933 -0.030851   \n",
       "509 -0.010746 -0.003816  0.023448  0.001317  0.002640 -0.183422  0.097341   \n",
       "510 -0.113499  0.025413 -0.255962 -0.002498 -0.016057  0.508644 -0.026986   \n",
       "511 -0.002495 -0.002812  0.069646  0.001373 -0.009951 -0.193975  0.074348   \n",
       "\n",
       "           7         8         9         10        11        12        13  \\\n",
       "0    0.019574  0.014512  0.031816 -0.001767  0.005286 -0.001798 -0.011941   \n",
       "1   -0.017151 -0.022757 -0.015226 -0.001958  0.002843  0.023895  0.024760   \n",
       "2    0.037840  0.008996 -0.017308  0.002658  0.004721 -0.010183  0.022277   \n",
       "3   -0.032054  0.009461 -0.016316 -0.000577 -0.003060  0.000590  0.025039   \n",
       "4   -0.014036  0.007418 -0.015662 -0.002117  0.002645  0.001849  0.028881   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "507  0.026715  0.008688  0.020754 -0.003117 -0.003833  0.000006  0.017209   \n",
       "508 -0.028827 -0.005917 -0.006023  0.000786 -0.001256 -0.000033 -0.042910   \n",
       "509  0.033691  0.007331  0.023418 -0.001231 -0.008805  0.000012  0.055271   \n",
       "510 -0.080468  0.008861 -0.006110 -0.001233  0.008284 -0.000049 -0.009533   \n",
       "511  0.025062  0.008997  0.021850 -0.002650 -0.007210  0.000013  0.056252   \n",
       "\n",
       "           14        15        16        17        18        19  \n",
       "0   -0.002266 -0.010339 -0.024124  0.028901 -0.006093  0.005533  \n",
       "1   -0.015642 -0.002737 -0.016819  0.029769 -0.093086  0.008109  \n",
       "2    0.013243 -0.000137 -0.026663 -0.020180 -0.122443  0.004120  \n",
       "3   -0.015776 -0.006022  0.004588  0.029983 -0.104112 -0.002858  \n",
       "4   -0.015081 -0.004178 -0.010822  0.031147 -0.126427  0.003352  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "507  0.006311 -0.061827 -0.016674 -0.029071  0.289541 -0.021307  \n",
       "508  0.009608 -0.012760 -0.027474 -0.030275 -0.072761 -0.021650  \n",
       "509  0.005284 -0.060763 -0.021611 -0.032990  0.267477 -0.010844  \n",
       "510  0.007906 -0.046510  0.662046 -0.027435 -0.079064  0.056893  \n",
       "511  0.003287 -0.061900 -0.047085 -0.032097  0.159083 -0.006506  \n",
       "\n",
       "[512 rows x 20 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaged_shap_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n"
     ]
    }
   ],
   "source": [
    "# plot \n",
    "shap.summary_plot(averaged_shap_values_df.values[:128], genomic.numpy() if isinstance(genomic, torch.Tensor) else genomic, show=True)\n",
    "plt.savefig(f'shap_summary_plot_{config_name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train the final model.\n",
    "models, optimizers = create_models_and_optimizers(config)\n",
    "lit_model = LitFullModel(models, optimizers, config)\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir=log_path,\n",
    "    max_epochs=config['max_epochs'],\n",
    "    enable_progress_bar=False,\n",
    "    log_every_n_steps=1,\n",
    "    logger=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plot the shap values\n",
    "shap.summary_plot(all_shap_values_folds, genomic, plot_type=\"bar\")\n",
    "shap.summary_plot(all_shap_values_folds, genomic)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-1.66985109e-01,  2.14320087e+00,  9.78210449e+01, ...,\n",
      "        -2.82952385e+01,  4.27113152e+00, -1.73556018e+00],\n",
      "       [-4.45447803e-01,  2.16152802e-01,  2.76926346e+01, ...,\n",
      "         6.42128658e+00, -1.75570316e+01, -1.45657551e+00],\n",
      "       [ 6.53261662e+00, -8.16797674e-01, -4.15763168e+01, ...,\n",
      "         6.38731670e+00,  1.19319239e+01, -1.02256620e+00],\n",
      "       ...,\n",
      "       [ 2.76738548e+00,  1.65761504e-02, -2.20396099e+01, ...,\n",
      "         6.13573408e+00,  1.44764309e+01, -1.91254008e+00],\n",
      "       [-1.77355364e-01,  1.81312785e-01, -3.22547791e+02, ...,\n",
      "         5.80760574e+00,  1.42741375e+01, -2.34771162e-01],\n",
      "       [-4.44778830e-01, -3.82962137e-01,  4.21823311e+01, ...,\n",
      "         5.67802954e+00, -2.69258366e+01,  5.79677820e-01]]), array([[-9.49228883e-01,  9.17250729e+00,  2.22483902e+01, ...,\n",
      "         2.05281799e+02,  3.33620529e+01, -1.28452158e+00],\n",
      "       [-2.53215432e+00,  9.25094783e-01,  6.29840231e+00, ...,\n",
      "        -4.65863838e+01, -1.37138992e+02, -1.07804000e+00],\n",
      "       [ 3.71347504e+01, -3.49574590e+00, -9.45609951e+00, ...,\n",
      "        -4.63399391e+01,  9.32009811e+01, -7.56821156e-01],\n",
      "       ...,\n",
      "       [ 1.57312365e+01,  7.09428713e-02, -5.01267767e+00, ...,\n",
      "        -4.45147362e+01,  1.13076241e+02, -1.41550815e+00],\n",
      "       [-1.00817895e+00,  7.75985777e-01, -7.33601685e+01, ...,\n",
      "        -4.21341286e+01,  1.11496140e+02, -1.73758686e-01],\n",
      "       [-2.52835155e+00, -1.63900733e+00,  9.59393311e+00, ...,\n",
      "        -4.11940613e+01, -2.10319321e+02,  4.29030836e-01]]), array([[-5.70657194e-01,  1.52919445e+01,  1.18339836e+02, ...,\n",
      "         3.00546661e+02,  5.10275955e+01, -7.95783901e+00],\n",
      "       [-1.52227962e+00,  1.54227161e+00,  3.35013847e+01, ...,\n",
      "        -6.82056961e+01, -2.09755554e+02, -6.67864704e+00],\n",
      "       [ 2.23246517e+01, -5.82792807e+00, -5.02972717e+01, ...,\n",
      "        -6.78448639e+01,  1.42551819e+02, -4.68864202e+00],\n",
      "       ...,\n",
      "       [ 9.45730209e+00,  1.18272506e-01, -2.66625900e+01, ...,\n",
      "        -6.51726379e+01,  1.72951279e+02, -8.76932621e+00],\n",
      "       [-6.06096804e-01,  1.29368424e+00, -3.90204773e+02, ...,\n",
      "        -6.16872978e+01,  1.70534454e+02, -1.07646608e+00],\n",
      "       [-1.51999378e+00, -2.73247027e+00,  5.10304146e+01, ...,\n",
      "        -6.03109665e+01, -3.21685333e+02,  2.65792179e+00]]), array([[ 6.52114034e-01,  1.87057095e+01,  1.06545311e+02, ...,\n",
      "        -2.98169899e+01, -4.13501587e+01,  1.02611578e+00],\n",
      "       [ 1.73957348e+00,  1.88656759e+00,  3.01624298e+01, ...,\n",
      "         6.76662874e+00,  1.69975174e+02,  8.61171603e-01],\n",
      "       [-2.55113258e+01, -7.12895155e+00, -4.52843094e+01, ...,\n",
      "         6.73083448e+00, -1.15516670e+02,  6.04572117e-01],\n",
      "       ...,\n",
      "       [-1.08072605e+01,  1.44675523e-01, -2.40052185e+01, ...,\n",
      "         6.46572256e+00, -1.40150864e+02,  1.13075173e+00],\n",
      "       [ 6.92612410e-01,  1.58248580e+00, -3.51314240e+02, ...,\n",
      "         6.11994314e+00, -1.38192368e+02,  1.38803825e-01],\n",
      "       [ 1.73696089e+00, -3.34246564e+00,  4.59443626e+01, ...,\n",
      "         5.98340082e+00,  2.60677490e+02, -3.42723131e-01]]), array([[-2.98196018e-01, -8.85456944e+00, -1.61003326e+02, ...,\n",
      "        -2.02853561e+02, -3.96806335e+01,  8.54199314e+00],\n",
      "       [-7.95464993e-01, -8.93029332e-01, -4.55792160e+01, ...,\n",
      "         4.60353317e+01,  1.63112350e+02,  7.16890383e+00],\n",
      "       [ 1.16657143e+01,  3.37457490e+00,  6.84303055e+01, ...,\n",
      "         4.57918053e+01, -1.10852707e+02,  5.03281593e+00],\n",
      "       ...,\n",
      "       [ 4.94189978e+00, -6.84838444e-02,  3.62749023e+01, ...,\n",
      "         4.39881821e+01, -1.34492233e+02,  9.41304970e+00],\n",
      "       [-3.16715032e-01, -7.49088585e-01,  5.30880066e+02, ...,\n",
      "         4.16357384e+01, -1.32612839e+02,  1.15548503e+00],\n",
      "       [-7.94270277e-01,  1.58219635e+00, -6.94277267e+01, ...,\n",
      "         4.07067947e+01,  2.50152573e+02, -2.85302997e+00]]), array([[-1.19722283e+00,  2.05718365e+01,  9.20206909e+01, ...,\n",
      "         9.45290680e+01,  5.49826527e+00,  1.47007310e+00],\n",
      "       [-3.19370031e+00,  2.07477546e+00,  2.60505753e+01, ...,\n",
      "        -2.14523048e+01, -2.26013241e+01,  1.23376489e+00],\n",
      "       [ 4.68365097e+01, -7.84015274e+00, -3.91109924e+01, ...,\n",
      "        -2.13388214e+01,  1.53600702e+01,  8.66145253e-01],\n",
      "       ...,\n",
      "       [ 1.98411560e+01,  1.59108520e-01, -2.07327480e+01, ...,\n",
      "        -2.04983387e+01,  1.86356449e+01,  1.61998081e+00],\n",
      "       [-1.27157414e+00,  1.74035764e+00, -3.03421875e+02, ...,\n",
      "        -1.94021130e+01,  1.83752232e+01,  1.98858410e-01],\n",
      "       [-3.18890357e+00, -3.67591810e+00,  3.96810760e+01, ...,\n",
      "        -1.89692287e+01, -3.46618767e+01, -4.91005123e-01]]), array([[-7.62455881e-01,  3.14043730e-01, -1.25490929e+02, ...,\n",
      "        -1.57100906e+02, -1.44843674e+01,  1.14044352e+01],\n",
      "       [-2.03392053e+00,  3.16729210e-02, -3.55258255e+01, ...,\n",
      "         3.56522980e+01,  5.95398560e+01,  9.57121658e+00],\n",
      "       [ 2.98280067e+01, -1.19685523e-01,  5.33366699e+01, ...,\n",
      "         3.54636841e+01, -4.04638367e+01,  6.71932411e+00],\n",
      "       ...,\n",
      "       [ 1.26359138e+01,  2.42890674e-03,  2.82737713e+01, ...,\n",
      "         3.40668716e+01, -4.90928383e+01,  1.25673771e+01],\n",
      "       [-8.09806943e-01,  2.65678056e-02,  4.13784119e+02, ...,\n",
      "         3.22450104e+01, -4.84068069e+01,  1.54269028e+00],\n",
      "       [-2.03086662e+00, -5.61154895e-02, -5.41140823e+01, ...,\n",
      "         3.15255890e+01,  9.13115921e+01, -3.80908537e+00]]), array([[-1.05138075e+00,  8.57078171e+00, -7.61238480e+01, ...,\n",
      "        -9.60074005e+01,  1.44330959e+01,  6.91555786e+00],\n",
      "       [-2.80465341e+00,  8.64407361e-01, -2.15502625e+01, ...,\n",
      "         2.17878017e+01, -5.93291054e+01,  5.80390787e+00],\n",
      "       [ 4.11310120e+01, -3.26641965e+00,  3.23544655e+01, ...,\n",
      "         2.16725407e+01,  4.03206024e+01,  4.07454538e+00],\n",
      "       ...,\n",
      "       [ 1.74241600e+01,  6.62889928e-02,  1.71510944e+01, ...,\n",
      "         2.08189163e+01,  4.89190636e+01,  7.62075901e+00],\n",
      "       [-1.11667466e+00,  7.25080073e-01,  2.51004883e+02, ...,\n",
      "         1.97055454e+01,  4.82354660e+01,  9.35475051e-01],\n",
      "       [-2.80044150e+00, -1.53148651e+00, -3.28260574e+01, ...,\n",
      "         1.92658863e+01, -9.09883499e+01, -2.30979967e+00]])]\n"
     ]
    }
   ],
   "source": [
    " # get SHAP values from trained model   \n",
    "feat_extractor = models['feat_ext']\n",
    "genomic_feat = feat_extractor.genomic_feature_extractor\n",
    "explanation = shap.DeepExplainer(genomic_feat, genomic)\n",
    "shap_values = explanation.shap_values(genomic)\n",
    "print(shap_values)\n",
    "# plot the SHAP values\n",
    "shap.summary_plot(shap_values, genomic.numpy()) #, feature_names = feature_ids )  # Convert to numpy if 'genomic' is a tensor\n",
    "#rename features\n",
    "\n",
    "\n",
    "plt.savefig('shap_values.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.35154796e+00, -4.98240113e-01,  3.16914101e+01, ...,\n",
       "          1.56756096e+01,  1.89143097e+02, -4.53237724e+01],\n",
       "        [-3.74804664e+00, -3.00861716e+00,  1.41481613e+02, ...,\n",
       "         -8.01826019e+01, -5.34535179e+01,  1.00351274e-01],\n",
       "        [-6.98538303e+00, -2.93630719e+00,  1.49345993e+02, ...,\n",
       "         -8.62959290e+00, -6.00711594e+01,  2.09687042e+00],\n",
       "        ...,\n",
       "        [ 1.27547228e+00,  1.35158479e+00, -6.35802879e+01, ...,\n",
       "          1.37708797e+01, -6.81951981e+01, -2.23266315e+01],\n",
       "        [-1.87641883e+00, -2.47394371e+00,  5.46146536e+00, ...,\n",
       "          1.24087152e+01,  1.66692993e+02, -4.75309086e+00],\n",
       "        [-1.17481737e+01,  3.50825310e-01, -1.03076248e+01, ...,\n",
       "          1.62941113e+01,  1.48519348e+02, -7.82805395e+00]],\n",
       "\n",
       "       [[ 2.71542817e-01, -2.71075159e-01, -1.61153774e+01, ...,\n",
       "          2.32843132e+01,  6.70378799e+01, -2.96517301e+00],\n",
       "        [-7.53029287e-01, -1.63688612e+00, -7.19447632e+01, ...,\n",
       "         -1.19102013e+02, -1.89454975e+01,  6.56515360e-03],\n",
       "        [-1.40345109e+00, -1.59754360e+00, -7.59438858e+01, ...,\n",
       "         -1.28182755e+01, -2.12909775e+01,  1.37181371e-01],\n",
       "        ...,\n",
       "        [ 2.56258309e-01,  7.35351086e-01,  3.23311920e+01, ...,\n",
       "          2.04550514e+01, -2.41703777e+01, -1.46065283e+00],\n",
       "        [-3.76996130e-01, -1.34598744e+00, -2.77720714e+00, ...,\n",
       "          1.84317245e+01,  5.90808716e+01, -3.10956597e-01],\n",
       "        [-2.36035609e+00,  1.90871999e-01,  5.24152470e+00, ...,\n",
       "          2.42030277e+01,  5.26396255e+01, -5.12126923e-01]],\n",
       "\n",
       "       [[-4.99634966e-02,  7.32338846e-01,  1.43897772e+01, ...,\n",
       "          2.28993267e-01, -1.16061539e+02, -6.67106450e-01],\n",
       "        [ 1.38556406e-01,  4.42221975e+00,  6.42410965e+01, ...,\n",
       "         -1.17132723e+00,  3.28000183e+01,  1.47703942e-03],\n",
       "        [ 2.58232981e-01,  4.31593561e+00,  6.78119507e+01, ...,\n",
       "         -1.26063332e-01,  3.68607216e+01,  3.08631714e-02],\n",
       "        ...,\n",
       "        [-4.71511744e-02, -1.98662925e+00, -2.88692303e+01, ...,\n",
       "          2.01168403e-01,  4.18457718e+01, -3.28618735e-01],\n",
       "        [ 6.93667009e-02,  3.63632965e+00,  2.47983003e+00, ...,\n",
       "          1.81269735e-01, -1.02285782e+02, -6.99592307e-02],\n",
       "        [ 4.34302092e-01, -5.15661180e-01, -4.68027592e+00, ...,\n",
       "          2.38028497e-01, -9.11340942e+01, -1.15218669e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.93375528e+00,  2.60483050e+00, -1.61160145e+01, ...,\n",
       "          9.76078033e+00, -4.83963959e+02,  3.41507683e+01],\n",
       "        [ 5.36259747e+00,  1.57292480e+01, -7.19475708e+01, ...,\n",
       "         -4.99275284e+01,  1.36772446e+02, -7.56131411e-02],\n",
       "        [ 9.99448299e+00,  1.53512068e+01, -7.59468460e+01, ...,\n",
       "         -5.37341690e+00,  1.53705170e+02, -1.57995915e+00],\n",
       "        ...,\n",
       "        [-1.82490909e+00, -7.06617212e+00,  3.23324471e+01, ...,\n",
       "          8.57475567e+00,  1.74492279e+02,  1.68227673e+01],\n",
       "        [ 2.68472505e+00,  1.29339333e+01, -2.77731657e+00, ...,\n",
       "          7.72657490e+00, -4.26520416e+02,  3.58137822e+00],\n",
       "        [ 1.68089409e+01, -1.83413768e+00,  5.24173260e+00, ...,\n",
       "          1.01459055e+01, -3.80019165e+02,  5.89831591e+00]],\n",
       "\n",
       "       [[ 6.75362945e-02,  8.59986424e-01,  1.92240983e-01, ...,\n",
       "          1.13108139e+01,  4.67472992e+01,  1.38639653e+00],\n",
       "        [-1.87288374e-01,  5.19302034e+00,  8.58231604e-01, ...,\n",
       "         -5.78561516e+01, -1.32112007e+01, -3.06960940e-03],\n",
       "        [-3.49056751e-01,  5.06820822e+00,  9.05937195e-01, ...,\n",
       "         -6.22672796e+00, -1.48467798e+01, -6.41405657e-02],\n",
       "        ...,\n",
       "        [ 6.37348220e-02, -2.33289981e+00, -3.85679841e-01, ...,\n",
       "          9.93644810e+00, -1.68546562e+01,  6.82943046e-01],\n",
       "        [-9.37639102e-02,  4.27014589e+00,  3.31294090e-02, ...,\n",
       "          8.95357418e+00,  4.11986885e+01,  1.45390898e-01],\n",
       "        [-5.87051690e-01, -6.05541646e-01, -6.25263527e-02, ...,\n",
       "          1.17570982e+01,  3.67070274e+01,  2.39450067e-01]],\n",
       "\n",
       "       [[ 5.00747621e-01,  1.16246253e-01, -9.88597095e-01, ...,\n",
       "          1.45168657e+01, -8.89110031e+01, -3.41500330e+00],\n",
       "        [-1.38864887e+00,  7.01951981e-01, -4.41344786e+00, ...,\n",
       "         -7.42555161e+01,  2.51270447e+01,  7.56110996e-03],\n",
       "        [-2.58807969e+00,  6.85080767e-01, -4.65877151e+00, ...,\n",
       "         -7.99169731e+00,  2.82378082e+01,  1.57992437e-01],\n",
       "        ...,\n",
       "        [ 4.72561687e-01, -3.15343320e-01,  1.98335505e+00, ...,\n",
       "          1.27529373e+01,  3.20567017e+01, -1.68224156e+00],\n",
       "        [-6.95212066e-01,  5.77204943e-01, -1.70367628e-01, ...,\n",
       "          1.14914665e+01, -7.83578415e+01, -3.58130336e-01],\n",
       "        [-4.35269165e+00, -8.18523541e-02,  3.21541250e-01, ...,\n",
       "          1.50896482e+01, -6.98149033e+01, -5.89819074e-01]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# get SHAP values for all the training data, going through all the batches\n",
    "all_shap_values = []\n",
    "for batch in train:\n",
    "    (genomic, clinical, index, project_id), (overall_survival, survival_time, vital_status) = batch\n",
    "    shap_values = explanation.shap_values(genomic)\n",
    "    all_shap_values.append(np.array(shap_values))\n",
    "\n",
    "all_shap_values = np.concatenate(all_shap_values, axis=1)\n",
    "all_shap_values\n",
    "# shap_values_df = pd.DataFrame(all_shap_values)\n",
    "\n",
    "# shap_values_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'corr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m correlation_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mall_shap_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m()\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m      3\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(correlation_matrix, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;124m\"\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoolwarm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'corr'"
     ]
    }
   ],
   "source": [
    "\n",
    "correlation_matrix = all_shap_values.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation matrix of SHAP values')\n",
    "plt.savefig('SHAPcorrelation_matrix.png')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "progpred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
