{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.dnn import Genomic_Feature_Extractor  \n",
    "import torch\n",
    "config_dims = {'genomic_dim': 20, 'genomic_embedding_dim': 8}\n",
    "model = Genomic_Feature_Extractor(genomic_dim=config_dims['genomic_dim'],\n",
    "            genomic_embedding_dim=config_dims['genomic_embedding_dim'])\n",
    "weights = torch.load('/home/zow/Multi-Cancer/Checkpoints/Trainer/tcga_multi_dnn_trainer_cross_validation_4_bootstrap_test/20230927152936/checkpoint-epoch50.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4250,  0.2636, -0.4603,  0.0733,  0.4305,  0.0300,  0.2570, -0.4492,\n",
       "         -0.1545,  0.1972,  0.1246,  0.0849, -0.1533, -0.1209,  0.2893,  0.5609,\n",
       "         -0.3924,  0.1108, -0.2439,  0.0524],\n",
       "        [ 0.3815,  0.0620, -0.3089,  0.1661,  0.0566,  0.2817, -0.0772, -0.0423,\n",
       "         -0.0132,  0.2168,  0.0512, -0.0400,  0.0677, -0.1994,  0.0775,  0.3982,\n",
       "         -0.0377,  0.1775, -0.5042, -0.3299],\n",
       "        [-0.5778, -0.1753, -0.0905,  0.1218,  0.1970, -0.3466, -0.4813,  0.1017,\n",
       "          0.8698, -0.2419,  0.1321, -0.1542,  0.0931, -0.3106,  0.6785, -0.3515,\n",
       "          0.4746, -0.3496,  0.2080, -0.2929],\n",
       "        [ 0.5740,  0.0574,  0.3716,  0.1401, -0.2224, -0.3132,  0.1873,  0.6987,\n",
       "          0.1025, -0.4229,  0.1138,  0.1346,  0.0536, -0.1835, -0.1689, -0.2796,\n",
       "         -0.1292, -0.0406, -0.0358,  0.0446],\n",
       "        [-0.0346, -0.0769, -0.2033,  0.1819, -0.3263,  0.0849, -0.0937,  0.0274,\n",
       "         -0.0865, -0.1790, -0.5308,  0.0269,  0.2954, -0.1072,  0.2203,  0.0983,\n",
       "          0.0342,  0.0402, -0.2839,  0.3313],\n",
       "        [ 0.0630,  0.4989,  0.3042, -0.5378,  0.0690,  0.1646,  0.3423,  0.0211,\n",
       "         -0.0093,  0.2694, -0.3698,  0.1624,  0.1382,  0.5021, -0.0414,  0.2170,\n",
       "          0.0308,  0.3621, -0.1512,  0.3851],\n",
       "        [ 0.1557, -0.0435,  0.1420,  0.4976, -0.6316, -0.1004, -0.0254,  0.4831,\n",
       "         -0.6759,  0.2813,  0.1134,  0.2483,  0.3299,  0.1651,  0.5239, -0.1422,\n",
       "          0.2472, -0.3237,  0.3587, -0.0315],\n",
       "        [-0.0849,  0.0750, -0.2225,  0.0218, -0.2945, -0.3637, -0.1594, -0.2843,\n",
       "         -0.2101, -0.1412, -0.1313,  0.3939,  0.1557,  0.4994, -0.1731,  0.0727,\n",
       "         -0.0115,  0.0317, -0.0618, -0.2759]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# get all the genomic feature extractor weights\n",
    "feat_extractor = weights['models']['Feature_Extractor']\n",
    "# get the first layer weights, feat_extractor is an ordered dict\n",
    "# first_key, first_value = next(iter(feat_extractor.items()))\n",
    "# first_key, first_value\n",
    "\n",
    "# transform ordered dict to a normal dict\n",
    "feat_extractor = dict(feat_extractor)\n",
    "# get the first layer weights\n",
    "first_layer_weights = feat_extractor['genomic_feature_extractor.genomic_feature_extractor.0.weight']\n",
    "first_layer_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "# get SHAP values\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from model.dnn import Genomic_Feature_Extractor\n",
    "\n",
    "from dataset import TCGA_Program_Dataset\n",
    "from datasets_manager import TCGA_Balanced_Datasets_Manager, TCGA_Datasets_Manager\n",
    "from lit_models import LitFullModel\n",
    "from model import Classifier, Feature_Extractor, Graph_And_Clinical_Feature_Extractor, Task_Classifier\n",
    "from utils import config_add_subdict_key, get_logger, override_n_genes, set_random_seed, setup_logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age_at_diagnosis', 'year_of_diagnosis', 'year_of_birth',\n",
      "       'gender_female', 'gender_male', 'race_american indian or alaska native',\n",
      "       'race_asian', 'race_black or african american', 'race_not reported',\n",
      "       'race_white', 'ethnicity_hispanic or latino',\n",
      "       'ethnicity_not hispanic or latino', 'ethnicity_not reported'],\n",
      "      dtype='object') df_clinical.columns 13\n",
      "Index(['age_at_diagnosis', 'year_of_diagnosis', 'year_of_birth',\n",
      "       'gender_female', 'gender_male', 'race_american indian or alaska native',\n",
      "       'race_asian', 'race_black or african american', 'race_not reported',\n",
      "       'race_white', 'ethnicity_hispanic or latino',\n",
      "       'ethnicity_not hispanic or latino', 'ethnicity_not reported'],\n",
      "      dtype='object') df_clinical.columns 13\n",
      "Index(['age_at_diagnosis', 'year_of_diagnosis', 'year_of_birth',\n",
      "       'gender_female', 'gender_male', 'race_american indian or alaska native',\n",
      "       'race_asian', 'race_black or african american', 'race_not reported',\n",
      "       'race_white', 'ethnicity_hispanic or latino',\n",
      "       'ethnicity_not hispanic or latino', 'ethnicity_not reported'],\n",
      "      dtype='object') df_clinical.columns 13\n",
      "clinical ids training models ('age_at_diagnosis', 'year_of_diagnosis', 'year_of_birth', 'gender_female', 'gender_male', 'race_american indian or alaska native', 'race_asian', 'race_black or african american', 'race_not reported', 'race_white', 'ethnicity_hispanic or latino', 'ethnicity_not hispanic or latino', 'ethnicity_not reported', 'race_native hawaiian or other pacific islander')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() takes 2 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m background, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))  \u001b[38;5;66;03m# Extract a batch as background, adjust as needed for your data\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Assuming 'model' is your trained model\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDeepExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/progpred/lib/python3.9/site-packages/shap/explainers/_deep/__init__.py:86\u001b[0m, in \u001b[0;36mDeep.__init__\u001b[0;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m TFDeep(model, data, session, learning_phase_flags)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m \u001b[43mPyTorchDeep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer\u001b[38;5;241m.\u001b[39mexpected_value\n",
      "File \u001b[0;32m~/anaconda3/envs/progpred/lib/python3.9/site-packages/shap/explainers/_deep/deep_pytorch.py:57\u001b[0m, in \u001b[0;36mPyTorchDeep.__init__\u001b[0;34m(self, model, data)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 57\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# also get the device everything is running on\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mdevice\n",
      "File \u001b[0;32m~/anaconda3/envs/progpred/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() takes 2 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "# read config yaml\n",
    "\n",
    "import yaml\n",
    "# Read the YAML file\n",
    "with open('/home/zow/Multi-Cancer/config/light/MTL_TCGA.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)  # This assumes your YAML file can be loaded as a dictionary\n",
    "\n",
    "# Convert the series-like config (if needed) and ensure it's a dictionary\n",
    "config = dict(config)\n",
    "\n",
    "# Load the data\n",
    "data = {'TCGA_BLC': TCGA_Program_Dataset(**config['datasets'])}\n",
    "  # Ensure config_add_subdict_key logic is applied within this function if needed\n",
    "\n",
    "manager = TCGA_Balanced_Datasets_Manager(datasets=data, config=config_add_subdict_key(config))\n",
    "for key, values in manager['TCGA_BLC']['dataloaders'].items():\n",
    "    if key == 'train':\n",
    "        train_loader = values\n",
    "    elif key == 'test':\n",
    "        test_loader = values\n",
    "\n",
    "# Prepare background dataset for SHAP\n",
    "# Note: DeepExplainer requires actual dataset not DataLoader, here's an example assuming you can extract a sample:\n",
    "background, _ = next(iter(train_loader))  # Extract a batch as background, adjust as needed for your data\n",
    "\n",
    "# Assuming 'model' is your trained model\n",
    "explainer = shap.DeepExplainer(model, background)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "progpred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
